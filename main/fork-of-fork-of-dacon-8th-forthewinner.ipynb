{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 코드 정리"},{"metadata":{},"cell_type":"markdown","source":"\n## 공통 함수 loading\n- 여러가지 인사이트 및 metric 값을 계산하기 위한 함수들을 정의하여 사용하였습니다.  \n  혹시 필요하시다면 참고하셔서 사용하셔도 좋을 듯 합니다. 최종 제출 코드에서는 RowVar 함수만 사용되었습니다.\n\n  - outlier_IQRTr : 수치형 자료에서 IQR 값을 계산하기 위한 함수.\n  - mkAUCValue    : testData에 대한 최종 AUC 값 평가에 사용한 함수.\n  - getPackages   : package에 dependency가 있는 package를 로딩하기 위한 함수\n  - RowVar        : 수치형 자료의 분산 값을 계산하기 위한 함수."},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_IQRTr <- function(x){\n  if(is.numeric(x)){\n    x.stats <- boxplot.stats(x)$out\n    x[x %in% x.stats] <- NA\n    as.numeric(x)\n  }else{\n    x\n  }\n}\n\nmkAUCValue <- function(YHat, Y){\n  # levels(Y)    <- c(0, 1)\n  # levels(YHat) <- c(0, 1)\n  pred <- prediction(YHat, Y)\n  # perf <- performance(pred, measure = \"tpr\", x.measure = \"fpr\")\n  auc <- performance(pred, measure = \"auc\")\n  auc@y.values[[1]]\n}\n\n\ngetPackages <- function(packs){\n  packages <- unlist(\n    tools::package_dependencies(packs, available.packages(),\n                                which=c(\"Depends\", \"Imports\"), recursive=TRUE)\n  )\n  packages <- union(packs, packages)\n  return(packages)\n}\n\n\n# row-wise variance\nRowVar <- function(x, ...) {\n  rowSums((x - rowMeans(x, ...))^2, ...)/(dim(x)[2] - 1)\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 라이브러리 & 데이터 로딩\n- 데이터 로딩시 일반적으로 사용하는 read.csv 등 함수를 사용할 수 있지만,  \n  빠른 데이터 로딩을 위하여 data.table library 내에 있는 fread 함수를 사용하였습니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"library(DMwR);library(dplyr);library(data.table);library(caret);library(catboost);\nlibrary(Matrix);library(ROCR);library(CatEncoders);library(foreach);library(matrixStats)\n##################\n## Data Loading ##\n##################\nsample_submission <- data.table::fread(\n  \"../input/dacon-8th/sample_submission.csv\",\n  stringsAsFactors = F,\n  data.table       = F\n)\n\ntrain <- data.table::fread(\n  \"../input/dacon-8th/train.csv\",\n  stringsAsFactors = F,\n  data.table = F,\n  na.strings = c(\"NA\", \"NaN\", \"NULL\", \"\\\\N\"))\n\ntest  <- data.table::fread(\n  \"../input/dacon-8th/test_x.csv\",\n  stringsAsFactors = F,\n  data.table = F,\n  na.strings = c(\"NA\", \"NaN\", \"NULL\", \"\\\\N\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering "},{"metadata":{},"cell_type":"markdown","source":"### 1. 이상치 및 결측치 처리\n- 분석 초반에는 Q_E와 familySize 변수들에 대해서 이상치 처리를 진행하였으나, 최종 평가에 있어 성능이 낮아져 최종 제출시 이상치 처리를 제외하였습니다.   \n- 분석 초반에는 LightGBM + CatBoost 앙상블 조합으로 성능을 개선하려고 생각하였기에 decision Tree 기반 모형인 두 모형에 대해서 이상치는 크게 영향을 미치지\n  않지 않을까 생각하여 제거하지 않았고, 그 이후에 특별한 조치는 하지 않았습니다  \n  (개인적으로 시간이 있었다면 이 부분에서 좀 더 개선할 수 있지 않았나 생각합니다)"},{"metadata":{},"cell_type":"markdown","source":"### 2. 파생변수 생성 및 변경\n- 저는 개인적으로 파생변수 생성에 많은 신경을 썼습니다. 지금까지 개최되었던 많은 대회들의 상위 커널들을 살펴보면, 좋은 파생변수를 생성하여 모델의 성능을 좋게하는 경우가 굉장히 많다고 생각하였습니다.\n\n- 우선 파생변수 생성 시 jhl님의 토론 공유 자료를 참고 하였습니다. 개인적으로 정말 신선한 접근 방식이라 많이 배울 수 있었습니다. 감사합니다.\n  https://dacon.io/competitions/official/235647/codeshare/1711?page=1&dtype=recent&ptype=pub\n\n\n- 파생변수 추가 여부를 판단하는 프로세스는 다음과 같습니다\n\n  - 수치형 파생변수 같은 경우, 대선투표 결과 기준으로 T-Test 분석을 수행해 p-value 값이 0.05보다 작은지 확인(이산형은 카이제곱검정을 수행하려 했음)\n  - 밀도 함수 그래프를 통하여 대선투표 결과 기준으로 차이가 나는지 시각적으로 확인(이산형은 막대 그래프)\n  - 모델 생성 후 variable importance에 상위에 rank하는지 우선 확인. 모델에 거의 영향을 미치지 않는 경우는 제외.\n  - 파생변수 추가 전 후로 하여 validationSet 및 testData(Public Score)의 AUC 값이 좋아진 경우, 해당 파생변수 추가 최종 결정.\n  \n- 판단에 있어 혼란스러웠던 점은 파생변수 추가 시 10-fold cross-validation 기반으로 AUC 값이 좋아져 추가했지만, 제출시에 Public Score 값이 낮아지는 경우가 꽤 있었습니다. 따라서 후반에는 Public Score 기준으로 파생변수 추가 여부를 최종 결정하였습니다.\n\n- <b/> 최종 추가 파생변수 : QAvar, machiaScore, wf_mean, wr_mean, voca_mean, tp_positive, tp_negative, tp_var, tp_mean </b>\n\n### 파생변수 List\n\n- QAVar : Q_A 변수들의 분산 값을 계산.\n- machiaScore : jhl님께서 공유해주신 마키아벨리니즘 테스트 스코어를 기반으로 '-' 에 해당하는 Q_A의 값을 reverse score 시킨 후(6-value), 평균 값 계산.\n- wf_mean : wf_(01~03) 변수의 평균값 계산\n- wr_mean : wr_(01~13) 변수의 평균값 계산\n- voca_mean : 교육 수준에 따라 대선 투표 여부에 차이가 있다는 것을 기반으로 허구 단어는 모른다고 설문하고, 실제 존재하는 단어는 확실히 안다고 설문한다면 정직성 등을 감안해 어느정도 판단 지표로서 활용 가능하다고 생각하였습니다. (wf_(01~03) - wr(01-13)) / 16  \n- tp_positive, tp_negative : 데이터 변수 설명에서 확인 결과, tp_(홀수번호)는 활발하고 에너지가 많은 성향을 가지는 부분이며  tp_(짝수번호)는 주로 조용하고 에너지가 덜한 성향을 가지는 부분임을 기반으로 홀수번호와 짝수번호들의 평균 값을 파생변수로 추가하였습니다.\n- tp_var : tp_(01~10) 변수들의 분산 값 계산\n- tp_mean : tp_(짝수번호)는 reverse score(7-value) 하여 전체 tp_(01~10)의 평균값 계산\n- QE_median : Q_E의 중앙값 계산\n- QE_min : Q_E의 최소값 계산"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# ###########################\n# ## 파생변수 생성 및 변경 ##\n# ###########################\n#- 1. reverse \n#- QaA, QdA, QeA, QfA, QgA, QiA, QkA, QnA, QqA, QrA --> reverse \nrevVar  <- c(\"QaA\", \"QdA\", \"QeA\", \"QfA\", \"QgA\", \"QiA\", \"QkA\", \"QnA\", \"QqA\", \"QrA\")\ntrain[revVar] <- train %>% select(revVar) %>% mutate_all(list(~6 - .))\ntest[revVar]  <- test %>% select(revVar) %>% mutate_all(list(~6 - .))\n\n# 2. QAvar\nQAvar <- train %>% select(matches(\"Q.A\")) %>%  colnames\ntrain$QA_var <- train %>% dplyr::select(c(QAvar)) %>% transmute(test = round(RowVar(across(where(is.numeric))), 4)) %>%  unlist %>% as.numeric\ntest$QA_var  <-  test %>% dplyr::select(c(QAvar)) %>% transmute(test = round(RowVar(across(where(is.numeric))), 4)) %>%  unlist %>% as.numeric\n\n#- 2. machia score = 전체 점수의 평균 값 계산\nmachiaVar             <- train %>% select(matches(\"Q.A\")) %>%  colnames\ntrain$machiaScore     <- train %>% select(machiaVar) %>% transmute(machiaScore = rowMeans(across(where(is.numeric)))) %>% unlist %>% as.numeric\ntest$machiaScore      <- test  %>% select(machiaVar) %>% transmute(machiaScore = rowMeans(across(where(is.numeric)))) %>% unlist %>% as.numeric\n\n#- 3 wf_mean, wr_mean, voca_mean(실제 단어를 아는 경우(wr)  - 허구인 단어를 아는 경우(wf) / 13)\nwfVar <- train %>% select(matches(\"wf.\")) %>%  colnames\nwrVar <- train %>% select(matches(\"wr.\")) %>%  colnames\n\n#- 3.1 wf_mean\ntrain$wf_mean <- train %>% select(wfVar) %>% transmute(wf_mean = round(rowMeans(across(where(is.numeric))), 8)) %>% unlist %>% as.numeric\ntest$wf_mean  <- test %>% select(wfVar)  %>% transmute(wf_mean = round(rowMeans(across(where(is.numeric))), 8)) %>% unlist %>% as.numeric\n\n#- 3.2 wr_mean\ntrain$wr_mean <- train %>% select(wrVar) %>% transmute(wr_mean = round(rowMeans(across(where(is.numeric))), 8)) %>% unlist %>% as.numeric\ntest$wr_mean  <- test %>% select(wrVar)  %>% transmute(wr_mean = round(rowMeans(across(where(is.numeric))), 8)) %>% unlist %>% as.numeric\n\n#- 3.3 voca_mean\ntrain$voca_mean <- train %>% transmute(voca_mean = round((\n    wr_01 + wr_02 + wr_03 + wr_04 + wr_05 + wr_06 + wr_07 + wr_08 + wr_09 + wr_10 + wr_11 + wr_12 + wr_13 - wf_01 - wf_02 - wf_03 / 16), 8)) %>% unlist %>% as.numeric\ntest$voca_mean <- test %>% transmute(voca_mean = round((wr_01 + wr_02 + wr_03 + wr_04 + wr_05 + wr_06 + wr_07 + wr_08 + wr_09 + wr_10 + wr_11 + wr_12 + wr_13 - wf_01 - wf_02 - wf_03 / 16), 8)) %>% unlist %>% as.numeric\n\n#- tp variable\ntpPs <- c(\"tp01\", \"tp03\", \"tp05\", \"tp07\", \"tp09\")\ntpNg <- c(\"tp02\", \"tp04\", \"tp06\", \"tp08\", \"tp10\")\n\n#- 3.4 tp_positive\ntrain$tp_positive  <- train %>% select(all_of(tpPs)) %>% transmute(tp_positive = round(rowMeans(across(where(is.numeric))), 8)) %>%  unlist %>% as.numeric \ntest$tp_positive   <- test  %>% dplyr::select(all_of(tpPs)) %>% transmute(tp_positive = round(rowMeans(across(where(is.numeric))), 8)) %>%  unlist %>% as.numeric \n\n#- 3.5 tp_negative \ntrain$tp_negative  <- train %>% dplyr::select(all_of(tpNg)) %>% transmute(tp_negative = round(rowMeans(across(where(is.numeric))), 8)) %>%  unlist %>% as.numeric \ntest$tp_negative   <- test  %>% dplyr::select(all_of(tpNg)) %>% transmute(tp_negative = round(rowMeans(across(where(is.numeric))), 8)) %>%  unlist %>% as.numeric \n\n#- 3.6 tp_variance\ntrain$tp_var       <- train %>% dplyr::select(c(tpPs, tpNg)) %>% transmute(test = round(RowVar(across(where(is.numeric))), 4)) %>%  unlist %>% as.numeric \ntest$tp_var        <- test %>% dplyr::select(c(tpPs, tpNg)) %>% transmute(test = round(RowVar(across(where(is.numeric))), 4)) %>%  unlist %>% as.numeric \n\n#- 3.7 tp_mean\ntrain$tp_mean <- train %>% transmute(tp_mean = round(((tp01 + tp03 + tp05 + tp07 + tp09 + (7 - tp02) + (7 - tp04) + (7 - tp06) + (7 - tp08) + (7 - tp10)) / 10), 8)) %>%  unlist %>% as.numeric\ntest$tp_mean  <- test %>% transmute(tp_mean = round(((tp01 + tp03 + tp05 + tp07 + tp09 + (7 - tp02) + (7 - tp04) + (7 - tp06) + (7 - tp08) + (7 - tp10)) / 10), 8)) %>%  unlist %>% as.numeric\n\n#- 4. QE derived Var\n#- 4.1 QE_median\n# QE_var          <- train %>% select(matches(\"Q.E\")) %>%  colnames\n# train$QE_median <- apply(train[, QE_var], 1,  median)\n# test$QE_median  <- apply(test[, QE_var], 1,   median)\n\n# #- 4.2 QE_min\n# train$QE_min <- apply(train[, QE_var], 1,  min)\n# test$QE_min  <- apply(test[, QE_var], 1,   min)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. 변수타입설정 & 변수 선택\n- 범주형 타입으로 변환이 필요한 변수들을 변환하였습니다.  \n- 구분 짓기는 어려웠지만, 범주형을 다시 명목형과 순서형으로 변환하였습니다  \n  구분한 이유는 CatBoost 모형 생성시 내부적으로 각각의 타입에 따라 다른 방식으로 encoding을 할 수도 있겠다고 판단하여 구분지었습니다.(큰 의미는 없지 않나 생각됩니다)\n- Index 변수는 제거하였습니다.\n- 한가지 특징적인 부분 중 하나는 파생변수로 생성하였던 QA_var 변수를 순서형 변수에 포함하였습니다.  \n  성능 판단시에 더 좋은 성능을 나타내어 순서형 변수로 추가하였습니다.  \n\n  \n### 추가 특이사항\n- 초기에는 one-hot encoding이나 label encoding을 한 후에 모델링을 진행했으나,  \n  encoding을 하지 않고 모델링 시 범주형 변수를 지정하여 모델링 하는 것이 더 성능이 좋았습니다  \n  (CatBoost 모델 특성상 내부적으로 범주형 변수인 경우 encoding을 수행하기 때문입니다)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"##############################\n## 변수타입설정 & 변수 선택 ##\n##############################\n#- 수치형 변수 \n\n#- 범주형(명목형) 변환\nfactor_var <- c(\"engnat\",\n                \"age_group\",\n                \"education\",\n                \"gender\",\n                \"hand\",\n                \"married\",\n                \"race\",\n                \"religion\",\n                \"urban\",\n                \"voted\")\n\nyIdx <- which(factor_var %in% c('voted'))\n\ntrain[factor_var]        <- train %>% dplyr::select(all_of(factor_var))        %>% mutate_all(as.factor)\ntest[factor_var[-yIdx]]  <-  test %>% dplyr::select(all_of(factor_var[-yIdx])) %>% mutate_all(as.factor)\n\n#- 범주형(순서형) 변환\nordered_var1 <- colnames(train)[grep(\"Q.A\", colnames(train))]\nordered_var2 <- colnames(train)[grep(\"tp|wr|wf.\", colnames(train))]\nordered_var2 <- c(ordered_var2, \"QA_var\")\n\ntrain[c(ordered_var1, ordered_var2)]   <- train %>% dplyr::select(all_of(ordered_var1), all_of(ordered_var2)) %>% mutate_all(as.ordered)\ntest[c(ordered_var1, ordered_var2) ]   <- test %>% dplyr::select(all_of(ordered_var1), all_of(ordered_var2)) %>% mutate_all(as.ordered)\n\n#-  변수 제거\nremv_var <- c(\"index\")\ntrain    <- train %>%  dplyr::select(-all_of(remv_var))\ntest     <- test  %>%  dplyr::select(-all_of(remv_var))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{},"cell_type":"markdown","source":"### 모델링 프로세스\n- 모델링 프로세스는 다음과 같습니다\n  - hyper parameter 조합별 모델 생성\n  - variable importance 상위 70개 변수 선택\n  - 70개 변수로 재 모델링\n  - 성능이 가장 잘나온 상위 3개 Catboost 모형 선택\n  - 3개 모형 앙상블\n  \n- 최종 소스에는 담겨있지 않지만, learningRate, maxDepth, l2_leaf_reg 3가지  \n  hyper parameter에 대해서 조합별로 AUC가 가장 높은 3개의 CatBoost 모형을 선택하였습니다.\n  \n- 상위 70개의 변수를 선택하였을 때 모델의 성능이 더 좋아졌습니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"############\n## 모델링 ##\n############\ntrainData <- train\ntestData  <- test\n\n#################\n## 2. CatBoost ##\n#################\n##- 기본 catBoost function을 이용한 모델 생성\n\n# voted  1 --> 0, 2 --> 1로 변경 \ntrainData_cat <- trainData\ntestData_cat  <- testData\nYIdx       <- which(colnames(trainData_cat) %in% c('voted'))\nfeatures   <- trainData_cat[-YIdx]\nlabels     <- ifelse(trainData_cat[,YIdx] == 1, 0, 1)\ntrain_pool <- catboost.load_pool(data  = features, \n                                 label = labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 모델 3개에 대해서 각각 모델링 -> 상위 70개 변수 선택 -> 재 모델링을 진행해야 하지만, 모델링 수행 시간이 너무 오래 걸려  \n  1개의 모델만 가지고 variable importance 기준 상위 70개 변수를 선택하고 해당 변수로 3개 모델을 모델링 하였습니다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"grid <- data.frame(\n  learningRate = c(0.01),\n  maxDepth     = c(4), \n  l2_leaf_reg  = c(3.5)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 상위 70개 변수 선택"},{"metadata":{"trusted":true},"cell_type":"code","source":"g <- grid[1, ]\n\n  depth             <- g$maxDepth\n  learning_rate     <- g$learningRate\n  l2_leaf_reg       <- g$l2_leaf_reg\n  \n  \n  # 2. catboost.train 함수를 이용하여 train\n  set.seed(1)\n  model <- catboost.train(\n    train_pool,                                  #- 학습에 사용하고자 하는 train_pool  \n    NULL,                                        #- \n    params = list(loss_function = 'Logloss',     #- loss function 지정(여기서는 분류모형이므로 Logloss)\n                  random_seed   = 123,           #- seed number\n                  custom_loss   = \"AUC\",         #- 모델링 할 때 추가로 추출할 값들 (train_dir로 지정한 곳으로 해당 결과를 파일로 내보내준다)\n                #  train_dir     = \"./model/CatBoost_R_output\", #- 모델링 한 결과를 저장할 directory\n                  iterations    = 1000,                         #- 학습 iteration 수\n                  border_count  = 32,\n                  depth         = depth,\n                  learning_rate = learning_rate,\n                  l2_leaf_reg   = l2_leaf_reg,\n                  metric_period = 10)            \n  )         \n  \n  \n  # catboost importance \n  catboost_imp           <- data.frame(model$feature_importances)\n  catboost_imp$variables <- rownames(model$feature_importances)\n  colnames(catboost_imp) <- c(\"importance\", 'variables')\n  catboost_imp           <- catboost_imp %>% arrange(-importance)\n  \n  finalVar <- catboost_imp$variables[1:70] # 70개 변수 선택\n  \n  trainData <- train[c(finalVar, \"voted\")]\n  testData  <- test[c(finalVar)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- CatBoost 3개 모형 앙상블\n- 좀 더 정밀한 예측을 위하여, 최종 값을 확률로 편성하였습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"grid <- data.frame(\n  learningRate = c(0.03, 0.03, 0.02),\n  maxDepth     = c(7, 5, 6), \n  l2_leaf_reg  = c(5, 7.5, 3.5)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testResult_Catboost <- foreach(i = 1:nrow(grid), .combine = function(a,b){ cbind(a, b)}) %do% {\n\n  g <- grid[i, ]\n  depth             <- g$maxDepth\n  learning_rate     <- g$learningRate\n  l2_leaf_reg       <- g$l2_leaf_reg\n  \n  \n  # voted  1 --> 0, 2 --> 1로 변경 \n  trainData_cat <- trainData\n  testData_cat  <- testData\n  YIdx       <- which(colnames(trainData_cat) %in% c('voted'))\n  features   <- trainData_cat[-YIdx]\n  labels     <- ifelse(trainData_cat[,YIdx] == 1, 0, 1)\n  train_pool <- catboost.load_pool(data  = features, \n                                   label = labels)\n    \n    \n  # 2. catboost.train 함수를 이용하여 train\n  set.seed(1)\n  model <- catboost.train(\n    train_pool,                                  #- 학습에 사용하고자 하는 train_pool  \n    NULL,                                        #- \n    params = list(loss_function = 'Logloss',     #- loss function 지정(여기서는 분류모형이므로 Logloss)\n                  random_seed   = 123,           #- seed number\n                  custom_loss   = \"AUC\",         #- 모델링 할 때 추가로 추출할 값들 (train_dir로 지정한 곳으로 해당 결과를 파일로 내보내준다)\n                 # train_dir     = \"./model/CatBoost_R_output\", #- 모델링 한 결과를 저장할 directory\n                  iterations    = 1000,                         #- 학습 iteration 수\n                  border_count  = 32,\n                  depth         = depth,\n                  learning_rate = learning_rate,\n                  l2_leaf_reg   = l2_leaf_reg,\n                  metric_period = 10)            \n  )         \n    \n  real_pool  <- catboost.load_pool(testData_cat)\n  YHat_cat   <- catboost.predict(\n    model, \n    real_pool,\n    prediction_type = c('Probability'))  # Probability, Class\n    \n  gridCom       <- paste0(depth, \"_\", learning_rate, \"_\", l2_leaf_reg)\n  tmp           <- data.frame(YHat_cat)  \n  colnames(tmp) <- gridCom\n  tmp\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"YHat_cat <- testResult_Catboost %>% transmute(finalScore = rowMeans(across(where(is.numeric)))) %>% unlist %>% as.numeric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save(testResult_Catboost, file = \"testResult_Catboost.RData\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}