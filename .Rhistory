summary %>% select((matches("mean")))
summary %>% select((matches("median")))
summary %>% select((matches("Q1")))
summary %>% select((matches("Q3")))
summary %>% select((matches("skewness")))
summary %>% select((matches("kurtosis")))
# 1.1.2. 결측치 처리
#- 결측치 확인(실제 데이터는 결측치를 포함하고 있었음)
colSums(is.na(df))
#- DMwR::centrallnputation function을 이용해 수치형 데이터 평균치로 대체
#- 원래는 각 등급별 평균치로 대체할 수도 있으나, 그렇게 되면 결측치들이
# - 그룹에 편향된 결과를 보일 수 있으므로, 단순 평균치로 대체한다
library(DMwR)
df <- DMwR::centralImputation(df)
df
summary(df)
# 1.1.3. 시각화 확인
# 3.1 등급별 고객이 구입한 총 물품의 평균치 확인 - 막대그래프
# 등급별로 총 물품의 평균치가 확실히 차이가 나는 것으로 보아 고객의 등급을 판정하는 모델을 생성할 때, 해당 독립변수를 추가한다면
# 좋은 모델을 생성할 수 있을 것이라 판단된다.
library(ggplot2)
df$amount / df$count
df$amount / df$count == Inf
sum(df$amount / df$count == Inf)
df$count(df$amount / df$count == Inf)
df$count[df$amount / df$count == Inf]
df$count
summary(v)
summary(df$count)
grade    <- c(1, 2, 3, 4, 5)
amountOfCsm <- c(1000, 2000, 3000, 4000, 5000)
amount   <- c(150000, 120000, 90000, 50000, 30000)
count    <- c(12, 9, 7, 5, 3)
df <- foreach(i = 1:5, .combine='rbind') %do% {
grade1 <- data.frame(
grade    = rep(grade[i], amountOfCsm[i]),
duration = round(rnorm(amountOfCsm[i], duration[i], 1), 0),
count    = round(rnorm(amountOfCsm[i], count[i],    1), 0),
amount   = round(rnorm(amountOfCsm[i], amount[i],   2), 0)
)
grade1
}
duration <- c(8,  6, 5, 4, 2)
summary(df)
df %>% mutate_all(., function(x) ifelse(x <= 0, 1, x))
test <- df %>% mutate_all(., function(x) ifelse(x <= 0, 1, x))
summary(test)
View(grade1)
# 분석 할 데이터 생성
# 구글링으로 데이터 찾기가 어려워 직접 데이터를 생성해서 테스트 하는 형식으로 진행해 보도록 하겠다.
# 실제 데이터는 다음과 같은 특징이 있었던 것으로 기억한다.
# 0. 등급이 높아질수록 고객의 수는 많아짐
# 1. 등급이 높아질수록 count 값은 커짐
# 2. 등급이 높아질수록 amount 값은 커짐
# 3. 등급이 높아질수록 duration 값도 커짐
# 각 등급별로 2000개의 row data 를 생성하여 임의의 데이터를 만들어 보겠다.
library(dplyr)
library(foreach)
grade    <- c(1, 2, 3, 4, 5)
amountOfCsm <- c(1000, 2000, 3000, 4000, 5000)
amount   <- c(150000, 120000, 90000, 50000, 30000)
duration <- c(8,  6, 5, 4, 2)
count    <- c(12, 9, 7, 5, 3)
df <- foreach(i = 1:5, .combine='rbind') %do% {
grade1 <- data.frame(
grade    = rep(grade[i], amountOfCsm[i]),
duration = round(rnorm(amountOfCsm[i], duration[i], 1), 0),
count    = round(rnorm(amountOfCsm[i], count[i],    1), 0),
amount   = round(rnorm(amountOfCsm[i], amount[i],   2), 0)
)
grade1
}
df <- df %>% mutate_all(., function(x) ifelse(x <= 0, 1, x))
library(dplyr);library(timeDate)
summary <- df %>% summarise_all(list(mean   = ~ mean(., na.rm = T),
median = ~ median(., na.rm = T),
Q1 = ~ quantile(., 0.25, na.rm = T),
Q3 = ~ quantile(., 0.75, na.rm = T),
skewness = ~ timeDate::skewness(.),
kurtosis = ~ timeDate::kurtosis(.)))
summary %>% select((matches("mean")))
summary %>% select((matches("median")))
summary %>% select((matches("Q1")))
summary %>% select((matches("Q3")))
summary %>% select((matches("skewness")))
# 1.1.2. 결측치 처리
#- 결측치 확인(실제 데이터는 결측치를 포함하고 있었음)
colSums(is.na(df))
summary %>% select((matches("kurtosis")))
#- DMwR::centrallnputation function을 이용해 수치형 데이터 평균치로 대체
#- 원래는 각 등급별 평균치로 대체할 수도 있으나, 그렇게 되면 결측치들이
# - 그룹에 편향된 결과를 보일 수 있으므로, 단순 평균치로 대체한다
library(DMwR)
df <- DMwR::centralImputation(df)
# 1.1.3. 시각화 확인
# 3.1 등급별 고객이 구입한 총 물품의 평균치 확인 - 막대그래프
# 등급별로 총 물품의 평균치가 확실히 차이가 나는 것으로 보아 고객의 등급을 판정하는 모델을 생성할 때, 해당 독립변수를 추가한다면
# 좋은 모델을 생성할 수 있을 것이라 판단된다.
library(ggplot2)
df <- df %>% mutate(grade = as.factor(grade))
df_ctByGrd <- df %>% group_by(grade) %>% summarise(meanCount = mean(count, na.rm = T ))
ggplot(data = df_ctByGrd, aes(x = grade, y = meanCount, fill = grade)) + geom_col() + geom_label(aes(label = round(meanCount, 4)),
nudge_x = 0, nudge_y = 0, fill = 'white')
df_deriv <- df %>% mutate(
durationGrd = case_when(
duration <= quantile(duration, 0.25) ~ "1",
duration > quantile(duration, 0.25) & duration <= quantile(duration, 0.5)  ~ "2",
duration > quantile(duration, 0.5) & duration  <= quantile(duration, 0.75) ~ "3",
TRUE  ~ "4"
),
amtPerCnt   = amount / count
) %>% mutate(customerGrd = case_when(amtPerCnt >= quantile(amtPerCnt, 0.7) ~ "1" ,
amtPerCnt <= quantile(amtPerCnt, 0.3) ~ "3",
TRUE ~ "2"))
df_deriv <- df_deriv %>% mutate_if(is.character, as.factor)
summary(df_deriv)
# 3.1 train Data / test Data 생성
# 등급별 데이터의 수가 불균형 하므로(1등급의 고객 수는 적고, 5등급의 고객 수는 많음), 등급별 층별 샘플링을 통해 비율을 맞춤
set.seed(123)
train_idx <- caret::createDataPartition(df_deriv[, "grade"], p = 0.7, list = F)
trainData <- df_deriv[train_idx,  ]
testData  <- df_deriv[-train_idx, ]
# 3.2 SOM 분석 수행
# 기존 원천 데이터 중 수치형 데이터 duration, count, amount를 가지고 SOM 분석을 수행하도록 하겠다.
library(kohonen)
num_col <- c('duration', 'count', 'amount')
trainData.sc <- scale(trainData[num_col])
testData.sc  <- scale(testData[num_col],
center = attr(trainData.sc,"scaled:center"),
scale  = attr(trainData.sc, "scaled:scale"))
SOM_model <- xyf(trainData.sc,
classvec2classmat(trainData$grade),           #-  classvec2classmat : one-hot encoding 해주는 function
grid       = somgrid(13, 13, "hexagonal"),    #-  grid : 13 x 13, hexagonal
rlen       = 100                              #-  rlen : 100
)
pos.prediction <- predict(SOM_model, newdata = testData.sc,  whatmap = 1)
table(testData$grade, pos.prediction$prediction[[2]])
# caret package를 이용하여, randomForest, Neural Networks, XGBoost, SVM 모델 생성 및 예측 수행
library(caret)
colnames(trainData)
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = 'rf',
metrics     = 'Accuracy',
# tuneGrid    = expand.grid(mtry = c(3)),
trControl   = trainControl(method = 'none', number = 3, repeats = 3, verboseIter = T)
)
modelResult
predict.train(
object = modelResult, # caret model 객체
newdata = testData, # 예측하고자 하는 data
type = c('raw') # 예측 타입
)
caret::confusionMatrix(
Yhat,
testData$grade
)
YHat <- predict.train(
object = modelResult, # caret model 객체
newdata = testData, # 예측하고자 하는 data
type = c('raw') # 예측 타입
)
caret::confusionMatrix(
Yhat,
testData$grade
)
caret::confusionMatrix(
YHat,
testData$grade
)
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = 'rf',
metrics     = 'Accuracy',
tuneGrid    = expand.grid(mtry = c(3)),
trControl   = trainControl(method = 'none', number = 3, repeats = 3, verboseIter = T)
)
#######################
# 1. caret model List #
#######################
caretModelList <- caret::modelLookup()
caretModelList
caretModelList$model[grep("nnet", caretModelList$model)]
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = 'rf',
metrics     = 'Accuracy',
# tuneGrid    = expand.grid(mtry = c(3)),
trControl   = trainControl(method = 'none', number = 3, repeats = 3, verboseIter = T)
)
modelResult
modelResult
modelResult$bestTune
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = 'rf',
metrics     = 'Accuracy'
)
caretModelList$model[grep("svmLinear", caretModelList$model)]
caretModelList$model[grep("XGTree", caretModelList$model)]
caretModelList$model[grep("XG", caretModelList$model)]
caretModelList$model[grep("xg", caretModelList$model)]
method <- 'rf'
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = method,
metrics     = 'Accuracy'
)
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = method,
metrics     = 'Accuracy',
caret::trainControl(method = 'none')
)
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = method,
metrics     = 'Accuracy',
trControl   =  caret::trainControl(method = 'none')
)
modelResult
YHat <- predict.train(
object = modelResult, # caret model 객체
newdata = testData, # 예측하고자 하는 data
type = c('raw') # 예측 타입
)
result <- caret::confusionMatrix(
YHat,
testData$grade
)
result
result$table
result$overall
result
result <- caret::confusionMatrix(
YHat,
testData$grade,
mode = "prec_recall"
)
result
result$table
result$overall
result$byClass
result$byClass["F1"]
result$byClass
str(result$byClass)
result$byClass[7]
result$byClass[,7]
data.frame("method" = method, "f1_score" = result$byClass[,7])
result$byClass[,7]
c(method, result$byClass[,7])
data.frame(c(method, result$byClass[,7]))
data.frame("method" = method, "f1_score" = result$byClass[,7])
# method <- 'rf'
eval_df <- data.frame()
# method <- 'rf'
eval_df <- data.frame("method" = NULL, "f1_score" = NULL)
eval_df
# method <- 'rf'
eval_df <- data.frame("method" = NA, "f1_score" = NA)
eval_df
for(method in c('rf', 'svmLinear', 'nnet', 'xgbTree')){
modelResult <- train(
formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd),
data        = trainData,
method      = method,
metrics     = 'Accuracy',
trControl   =  caret::trainControl(method = 'none')
)
YHat <- predict.train(
object = modelResult, # caret model 객체
newdata = testData, # 예측하고자 하는 data
type = c('raw') # 예측 타입
)
result <- caret::confusionMatrix(
YHat,
testData$grade,
mode = "prec_recall"
)
rbind(eval_df, data.frame("method" = method, "f1_score" = result$byClass[,7]))
}
modelResult
# 0. 공통 변수 생성
f =    formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd)
# 0. 공통 변수 생성
f = formula(grade ~ duration  + count + amount + durationGrd + amtPerCnt + customerGrd)
# 1. randomForest 생성
modelResult <- train(
f,
data        = trainData,
method      = 'rf',
metrics     = 'Accuracy',
trControl   =  caret::trainControl(method = 'none')
)
YHat <- predict.train(
object  = modelResult,    #- caret model 객체
newdata = testData,       #- 예측하고자 하는 data
type    = c('raw')        #- 예측 타입
)
result <- caret::confusionMatrix(
YHat,
testData$grade,
mode = "prec_recall"
)
result
#######################
# 5. 모델 결과 시각화 #
#######################
# 수치 예측 PLOT
plot2 <- data.frame('Y'     = Y,
'YHat'  = Yhat,
'resid' = NA,
'index' = 1:nrow(modelResult$trainingData))
ROCR::prediction(
YHat,  # 예측 값
testData$grade         # 실제 값
)
YHat
testData$grade
library(ROCR)
ROCR::prediction(
YHat,                  # 예측 값
testData$grade         # 실제 값
)
YHat
prediction
YHat
ROCR::prediction
multiclass.roc
ibrary(pROC)
install.packages("pROC")
install.packages("pROC")
library(pROC)
pROC::multiclass.roc(
YHat,                  # 예측 값
testData$grade         # 실제 값
)
multiclass.roc
as.ordered(y_pred)
as.ordered(YHat)
YHat
pROC::multiclass.roc(
as.ordered(YHat),                  # 예측 값
testData$grade         # 실제 값
)
pROC::multiclass.roc(
as.ordered(YHat),                  # 예측 값
as.ordered(testData$grade)         # 실제 값
)
auc <- pROC::multiclass.roc(
as.ordered(YHat),                  # 예측 값
as.ordered(testData$grade)         # 실제 값
)
auc
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
plot(auc)
auc <- pROC::multiclass.roc(
as.ordered(YHat),                  # 예측 값
as.ordered(testData$grade)         # 실제 값
levels = c(1, 2, 3, 4, 5)
)
auc <- pROC::multiclass.roc(
as.ordered(YHat),                  # 예측 값
as.ordered(testData$grade),         # 실제 값
levels = c(1, 2, 3, 4, 5)
)
auc
print(auc)
plot(auc)
data(iris)
library(randomForest)
library(pROC)
set.seed(1000)
# 3-class in response variable
rf = randomForest(Species~., data = iris, ntree = 100)
rf
# predict(.., type = 'prob') returns a probability matrix
multiclass.roc(iris$Species, predict(rf, iris, type = 'prob'))
# predict(.., type = 'prob') returns a probability matrix
roc <- multiclass.roc(iris$Species, predict(rf, iris, type = 'prob'))
roc
install.packages("AppliedPredictiveModeling")
apropos
# apropos function
# 관심있는 class나 함수를 찾는데 유용한 함수
apropos("confusion")
library(AppliedPredictiveModeling)
# apropos function
# 관심있는 class나 함수를 찾는데 유용한 함수
apropos("confusion")
# 모든 패키지 중에서 함수를 찾아야 할 경우
# RSiteSearch function
# 모든 패키지 중에서 함수를 찾아야 할 경우
RSiteSearch("confusion", restrict = "functions")
data("segmentationOriginal")
segData <- subset(segmentationOriginal, Case == "Train")
segData
colnames(segData)
cellID <- segData$Cell
cellID
class  <- segData$Class
case   <- segData$Case
segData <- segData[, -c(1:3)]
# 원본 데이터에는 예측 변수의 바이너리 형태인 여러 "상태(status)" 관련 컬럼이 포함돼 있음
# 이 컬럼들을 제거하려면 컬럼 이름에 "Status"가 포함된 컬럼을 찾아야 함. 이들을 제거하자
grep("Status", colnames(segData))
# 원본 데이터에는 예측 변수의 바이너리 형태인 여러 "상태(status)" 관련 컬럼이 포함돼 있음
# 이 컬럼들을 제거하려면 컬럼 이름에 "Status"가 포함된 컬럼을 찾아야 함. 이들을 제거하자
statusColNum <- grep("Status", colnames(segData))
segData <- segData[,-statusColNum]
##########
## 변환 ##
##########
library(e1071)
skewValues <- apply(segData, 2, skewness)
skewValues
head(skewValues)
# caret package의 BoxCoxTrans function을 통해 적절한 변환법을 찾은 후,
# 이 방법을 적용해 새 데이터를 만들어 줌
library(caret)
Ch1AreaTrans <- BoxCoxTrans(segData$AreaCh1)
Ch1AreaTrans
predict(Ch1AreaTrans, head(segData$AreaCh1))
ion을 이용하여 PCA 적용
# 중심화 및 척도화 진행
# prcomp function을 이용하여 PCA 적용
# 중심화 및 척도화 진행
prcomp(
segData,
center = T,
scale  = T
)
# prcomp function을 이용하여 PCA 적용
# 중심화 및 척도화 진행
pcaObject <- prcomp(
segData,
center = T,
scale  = T
)
pcaObject
pcaObject$sdev^2
pcaObject$sdev^2 / sum(pcaObject$sdev^2)*100
pcaObject$sdev^2 / sum(pcaObject$sdev^2)*100
pcaObject$sd^2 / sum(pcaObject$sdev^2)*100
pcaObject$sd^2 / sum(pcaObject$sd^2)*100
sum(pcaObject$sd^2)*100
pcaObject$sd^2
percentVariance <- pcaObject$sd^2 / sum(pcaObject$sd^2)*100
percentVariance
percentVariance[1:3]
# 변환된 값은 x라고 불리는 하위 객체 형태로 저장
pcaObject$x[, 1:5]
# 변환된 값은 x라고 불리는 하위 객체 형태로 저장
head(pcaObject$x[, 1:5])
head(pcaObject$rotation[,1:3])
# 다양한 변환 #
###############
# caret::preProcess 사용
###############
# 다양한 변환 #
###############
# caret::preProcess 사용
trans <- preProcess(
segData,
method = c("BoxCox", "center", "scale", "pca"))
predict(trans, segData)
transformed <- predict(trans, segData)
head(transformed)
head(transformed[, c(1:5)])
nearZeroVar
# 예측 변수 간 상관관계를 기준으로 변수 filtering
correlations <- cor(segData)
correlations
dim(nearZeroVar)
dim(correlations)
correlations[1:4, 1:4]
corrplot::corrplot(correlations, order = 'hclust')
# findCorrelation function
# 3.5장에 나오는 상관변수 filtering algorithm 적용
findCorrelation(correlations, cutoff = 0.7)
# findCorrelation function
# 3.5장에 나오는 상관변수 filtering algorithm 적용
# 대상 예측 변수 후보를 고른 후, 해당 열의 번호 반환
highCor <- findCorrelation(correlations, cutoff = 0.7)
length(highCor)
filteredSegData <- segData[,-highCor]
filteredSegData
## monthly dacon 8
library(data.table)
train <- data.table::fread("train.csv")
## monthly dacon 8
getwd()
setwd("./monthlyDacon_8/")
library(data.table)
train <- data.table::fread("train.csv")
head(train)
View(train)
summary(train)
nrow(train)
ncol(train)
View(head(train))
