lgb.model = lgb.train(
params              = lgb.grid,
data                = lgb.train,
learning_rate       = 0.02,                        #- *** 훈련량
num_leaves          = 25,                          #- * 트리가 가질수 있는 최대 잎사귀 수
num_threads         = 2 ,                          #- * 병렬처리시 처리할 쓰레드
nrounds             = best.iter,                   #- *** 계속 나무를 반복하며 부스팅을 하는데 몇번을 할것인가이다. 1000이상정도는 해주도록 함
#-     early_stopping이 있으면 최대한 많이 줘도 (10,000~)별 상관이 없음
eval_freq           = 20,
eval                = lgb.normalizedgini,
categorical_feature = categoricals.vec)
lgb.model
lgb.model = lgb.train(
params              = lgb.grid,
data                = lgb.train,
learning_rate       = 0.02,                        #- *** 훈련량
num_leaves          = 25,                          #- * 트리가 가질수 있는 최대 잎사귀 수
num_threads         = 2 ,                          #- * 병렬처리시 처리할 쓰레드
nrounds             = best.iter,                   #- *** 계속 나무를 반복하며 부스팅을 하는데 몇번을 할것인가이다. 1000이상정도는 해주도록 함
#-     early_stopping이 있으면 최대한 많이 줘도 (10,000~)별 상관이 없음
eval_freq           = 20,
eval                = lgb.normalizedgini,
categorical_feature = categoricals.vec)
lgb.model
test_sparse
#- Create and Submit Predictions
pred <- target=predict(lgb.model,test_sparse)
#- Create and Submit Predictions
pred <- predict(lgb.model, test_sparse)
p
pred
View(pred)
train
agaricus.train
data(agaricus.train, package='lightgbm')
agaricus.train
library(data.table)
library(Matrix)
library(dplyr)
library(MLmetrics)
library(lightgbm)
setwd("C:/r")
set.seed(257)
train = fread("train.csv") %>% as.data.frame()
test  = fread("test.csv")  %>% as.data.frame()
train
# 결측치 --> median 치환 function
median.impute = function(x){
x = as.data.frame(x)
for (i in 1:ncol(x)){
x[which(x[,i]== -1),i] = NA
}
x = x %>% mutate_all(~ifelse(is.na(.), median(., na.rm = TRUE), .)) %>% as.data.table()
return(x)
}
#- Pre Processing
train = median.impute(train)
test  = median.impute(test)
#- Feature Engineering
test$target = NA
data        = rbind(train, test)
data[, fe_amount_NA := rowSums(data == -1, na.rm = T)]
data[, ps_car_13_ps_reg_03 := ps_car_13*ps_reg_03]
data[, ps_reg_mult := ps_reg_01*ps_reg_02*ps_reg_03]
data
#- Create LGB Dataset
varnames = setdiff(colnames(data), c("id", "target"))
train_sparse = Matrix(as.matrix(data[!is.na(target), varnames, with = F]), sparse=TRUE)
train_sparse
data[c("target")]
data[,c("target")]
data
train[,c("target")]
train
library(data.table)
library(Matrix)
library(dplyr)
library(MLmetrics)
library(lightgbm)
setwd("C:/r")
set.seed(257)
train = fread("train.csv") %>% as.data.frame()
test  = fread("test.csv")  %>% as.data.frame()
train[,c("target")]
library(DMwR);library(dplyr);library(data.table);library(caret);library(catboost);library(Matrix);library(ROCR);library(lightgbm)
setwd("C:/r/Monthly-Dacon-8th/")
source('C:/r/Monthly-Dacon-8th/monthlyDacon_8_common.R')
##################
## Data Loading ##
##################
sample_submission <- data.table::fread(
"sample_submission.csv",
stringsAsFactors = F,
data.table       = F
)
train <- data.table::fread(
"train.csv",
stringsAsFactors = F,
data.table = F,
na.strings = c("NA", "NaN", "NULL", "\\N"))
test  <- data.table::fread(
"test_x.csv",
stringsAsFactors = F,
data.table = F,
na.strings = c("NA", "NaN", "NULL", "\\N"))
num_var <- train %>%  select_if(is.numeric) %>%  colnames
#- 범주형(명목형) 변환
factor_var <- c("engnat",
"age_group",
"gender",
"hand",
"married",
"race",
"religion",
"urban",
"voted")
train[factor_var] <- train %>% select(all_of(factor_var))        %>% mutate_all(as.factor)
test[factor_var]  <-  test %>% select(all_of(factor_var[c(-9)])) %>% mutate_all(as.factor)
#- 범주형(순서형) 변환
ordered_var1 <- colnames(train)[grep("Q.A", colnames(train))]
ordered_var2 <- colnames(train)[grep("tp|wr|wf.", colnames(train))]
train[c(ordered_var1, ordered_var2)]   <- train %>% select(all_of(ordered_var1), all_of(ordered_var2)) %>% mutate_all(as.ordered)
test[c(ordered_var1, ordered_var2) ]   <- test %>% select(all_of(ordered_var1), all_of(ordered_var2)) %>% mutate_all(as.ordered)
#-  변수 제거
remv_var <- c("index")
train    <- train %>%  select(-remv_var)
test     <- test  %>%  select(-remv_var)
#- one-hot encoding (필요시)
oneHotVar       <- c(factor_var[-9])
train_fac       <- train %>% select(all_of(oneHotVar))
dmy_model       <- caret::dummyVars("~ .", data = train_fac)
train_oneHot    <- data.frame(predict(dmy_model, train_fac))
train  <- train %>% select(-oneHotVar)
train  <- dplyr::bind_cols(train, train_oneHot)
test_fac       <- test %>% select(all_of(oneHotVar[c(-9)]))
dmy_model      <- caret::dummyVars("~ .", data = test_fac)
test_oneHot    <- data.frame(predict(dmy_model, test_fac))
test  <- test %>% select(-oneHotVar)
test  <- dplyr::bind_cols(test, test_oneHot)
colnames(train)
View(head(train))
set.seed(1)
trainIdx <- createDataPartition(train[,"voted"], p = 0.7, list = F)
trainData <- train[ trainIdx, ]
testData  <- train[-trainIdx, ]
#################
## 5. LightGBM ##
#################
varnames = setdiff(colnames(trainData), c("voted"))
train_sparse = Matrix(as.matrix(trainData[, varnames]), sparse=TRUE)
test_sparse  = Matrix(as.matrix(testData[,  varnames]), sparse=TRUE)
ifelse(trainData[, "voted"] == 2, 1, 0)
y_train   = ifelse(trainData[, "voted"] == 2, 1, 0)
lgb.train = lgb.Dataset(
data  = train_sparse,
label = as.factor(y_train))
varnames
categoricals.vec <- c(ordered_var1, ordered_var2)
categoricals.vec <- c(categoricals.vec, colnames(trainData)[grep(paste(oneHotVar, collapse = "|"), colnames(trainData))])
lgb.grid = list(objective = "binary",
metric    = "auc",
min_sum_hessian_in_leaf = 1,
feature_fraction = 0.7,
bagging_fraction = 0.7,
bagging_freq = 5,
min_data = 100,
max_bin = 50,
lambda_l1 = 8,
lambda_l2 = 1.3,
min_data_in_bin=100,
min_gain_to_split = 10,
min_data_in_leaf = 30,
is_unbalance = F)
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
nrounds               = 7000,
early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
nfold                 = 5,
stratified            = TRUE)
lgb.model.cv
lgb.train
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
#num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
nrounds               = 7000,
early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
nfold                 = 5,
stratified            = TRUE)
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
#learning_rate         = 0.02,                    #- *** 훈련량
#num_leaves            = 25,
#num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
#nrounds               = 7000,
early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
#categorical_feature   = categoricals.vec,
#nfold                 = 5,
stratified            = TRUE)
lgb.model.cv
train_sparse
train_sparse
as.factor(y_train)
categoricals.vec
categoricals.vec
lgb.train = lgb.Dataset(
data  = train_sparse,
label = as.factor(y_train))
train_sparse = Matrix(as.matrix(trainData[, varnames]), sparse=TRUE)
test_sparse  = Matrix(as.matrix(testData[,  varnames]), sparse=TRUE)
Matrix
lgb.grid = list(objective = "binary",
metric    = "auc")
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
nrounds               = 7000,
early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
nfold                 = 5,
stratified            = TRUE)
lgb.model.cv
lgb.train
lgb.grid
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
# nrounds               = 7000,
# early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
# nfold                 = 5,
stratified            = TRUE)
best.iter = lgb.model.cv$best_iter
best.iter
lgb.model = lgb.train(
params              = lgb.grid,
data                = lgb.train,
learning_rate       = 0.02,                        #- *** 훈련량
num_leaves          = 25,                          #- * 트리가 가질수 있는 최대 잎사귀 수
num_threads         = 2 ,                          #- * 병렬처리시 처리할 쓰레드
nrounds             = best.iter,                   #- *** 계속 나무를 반복하며 부스팅을 하는데 몇번을 할것인가이다. 1000이상정도는 해주도록 함
#-     early_stopping이 있으면 최대한 많이 줘도 (10,000~)별 상관이 없음
eval_freq           = 20,
eval                = lgb.normalizedgini,
categorical_feature = categoricals.vec)
lgb.model
#- Create and Submit Predictions
pred <- predict(lgb.model, test_sparse)
pred
all(pred == 1)
pred == 1
pred
pred == 1
pred
str(pred)
pred == 1
pred[1] == 1
pred[1]
pred[1] == 1
pred
pred[1]
pred[1] == 1
train[,"voted"]
trainIdx <- createDataPartition(train[,"voted"], p = 0.7, list = F)
trainData <- train[ trainIdx, ]
testData  <- train[-trainIdx, ]
trainData
testData
varnames
colSums(is.na(train_sparse))
lgb.grid = list(objective = "binary",
metric    = "auc")
lgb.grid
lgb.grid
lgb.train
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
#num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
# nrounds               = 7000,
# early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
# nfold                 = 5,
stratified            = TRUE)
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
#num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
# nrounds               = 7000,
# early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec,
# nfold                 = 5,
#stratified            = TRUE
)
lgb.grid = list(objective = "binary",
metric    = "auc")
#- Cross Validation
lgb.model.cv = lgb.cv(
params                = lgb.grid,
data                  = lgb.train,
learning_rate         = 0.02,                    #- *** 훈련량
#num_leaves            = 25,
num_threads           = 2,                       #- * 병렬처리시 처리할 쓰레드
# nrounds               = 7000,
# early_stopping_rounds = 50,                      #- ** 더이상 발전이 없으면 그만두게 설정할때 이를 몇번동안 발전이 없으면 그만두게 할지 여부
#eval_freq             = 20,
#eval                  = lgb.normalizedgini,
categorical_feature   = categoricals.vec
# nfold                 = 5,
#stratified            = TRUE
)
lgb.model.cv
set.seed(1)
trainIdx <- createDataPartition(train[,"voted"], p = 0.7, list = F)
trainData <- train[ trainIdx, ]
testData  <- train[-trainIdx, ]
varnames
train_sparse = Matrix(as.matrix(trainData[, varnames]), sparse=TRUE)
test_sparse  = Matrix(as.matrix(testData[,  varnames]), sparse=TRUE)
tiny_train
dtrain <- lgb.Dataset(data=as.matrix(trainData[, varnames]), label = trainData$voted)
dtrain
dtrain <- lgb.Dataset(data=as.matrix(trainData[, varnames]), label = trainData$voted)
dvalid <- lgb.Dataset(data=as.matrix(testData[,  varnames]), label = testData$voted)
params.lgb = list(
objective = "binary"
, metric = "auc"
)
model <-  lgb.train(
params = params.lgb
, data = dtrain
, valids = list(train = dtrain, test = dvalid)
, learning_rate = 0.001
, nrounds = 500
, early_stopping_rounds = 40
, eval_freq = 20
, categorical_feature = names_char
)
categoricals.vec <- c(ordered_var1, ordered_var2)
categoricals.vec <- c(categoricals.vec, colnames(trainData)[grep(paste(oneHotVar, collapse = "|"), colnames(trainData))])
params.lgb = list(
objective = "binary"
, metric = "auc"
)
model <-  lgb.train(
params = params.lgb
, data = dtrain
, valids = list(train = dtrain, test = dvalid)
, learning_rate = 0.001
, nrounds = 500
, early_stopping_rounds = 40
, eval_freq = 20
, categorical_feature = names_char
)
model <-  lgb.train(
params = params.lgb
, data = dtrain
, valids = list(train = dtrain, test = dvalid)
, learning_rate = 0.001
, nrounds = 500
, early_stopping_rounds = 40
, eval_freq = 20
, categorical_feature = categoricals.vec
)
varnames
dtrain <- lgb.Dataset(data=as.matrix(trainData[, varnames]), label = ifelse(trainData$voted == 2, 1, 0))
dvalid <- lgb.Dataset(data=as.matrix(testData[,  varnames]), label = ifelse(testData$voted == 2, 1, 0))
dtrain
as.matrix(trainData[, varnames])
trainData[, varnames]
# train_sparse = Matrix(as.matrix(trainData[, varnames]), sparse=TRUE)
# test_sparse  = Matrix(as.matrix(testData[,  varnames]), sparse=TRUE)
str(trainData[, varnames])
library(DMwR);library(dplyr);library(data.table);library(caret);library(catboost);library(Matrix);library(ROCR);library(lightgbm)
setwd("C:/r/Monthly-Dacon-8th/")
source('C:/r/Monthly-Dacon-8th/monthlyDacon_8_common.R')
sample_submission <- data.table::fread(
"sample_submission.csv",
stringsAsFactors = F,
data.table       = F
)
train <- data.table::fread(
"train.csv",
stringsAsFactors = F,
data.table = F,
na.strings = c("NA", "NaN", "NULL", "\\N"))
test  <- data.table::fread(
"test_x.csv",
stringsAsFactors = F,
data.table = F,
na.strings = c("NA", "NaN", "NULL", "\\N"))
##############################
## 변수타입설정 & 변수 선택 ##
##############################
#- 수치형 변수
num_var <- train %>%  select_if(is.numeric) %>%  colnames
#- 범주형(명목형) 변환
factor_var <- c("engnat",
"age_group",
"gender",
"hand",
"married",
"race",
"religion",
"urban",
"voted")
train[factor_var] <- train %>% select(all_of(factor_var))        %>% mutate_all(as.factor)
test[factor_var]  <-  test %>% select(all_of(factor_var[c(-9)])) %>% mutate_all(as.factor)
#-  변수 제거
remv_var <- c("index")
train    <- train %>%  select(-remv_var)
test     <- test  %>%  select(-remv_var)
#- one-hot encoding (필요시)
oneHotVar       <- c(factor_var[-9])
train_fac       <- train %>% select(all_of(oneHotVar))
dmy_model       <- caret::dummyVars("~ .", data = train_fac)
train_oneHot    <- data.frame(predict(dmy_model, train_fac))
train  <- train %>% select(-oneHotVar)
train  <- dplyr::bind_cols(train, train_oneHot)
test_fac       <- test %>% select(all_of(oneHotVar[c(-9)]))
dmy_model      <- caret::dummyVars("~ .", data = test_fac)
test_oneHot    <- data.frame(predict(dmy_model, test_fac))
test  <- test %>% select(-oneHotVar)
test  <- dplyr::bind_cols(test, test_oneHot)
colnames(train)
str(train)
set.seed(1)
trainIdx <- createDataPartition(train[,"voted"], p = 0.7, list = F)
trainData <- train[ trainIdx, ]
testData  <- train[-trainIdx, ]
#################
## 5. LightGBM ##
#################
varnames = setdiff(colnames(trainData), c("voted"))
dtrain <- lgb.Dataset(data=as.matrix(trainData[, varnames]), label = ifelse(trainData$voted == 2, 1, 0))
dvalid <- lgb.Dataset(data=as.matrix(testData[,  varnames]), label = ifelse(testData$voted == 2, 1, 0))
dtrain
categoricals.vec <- c(ordered_var1, ordered_var2)
categoricals.vec <- c(categoricals.vec, colnames(trainData)[grep(paste(oneHotVar, collapse = "|"), colnames(trainData))])
params.lgb = list(
objective = "binary"
, metric = "auc"
)
model <-  lgb.train(
params = params.lgb
, data = dtrain
, valids = list(train = dtrain, test = dvalid)
, learning_rate = 0.001
, nrounds = 500
, early_stopping_rounds = 40
, eval_freq = 20
, categorical_feature = categoricals.vec
)
categoricals.vec <- c(ordered_var1, ordered_var2)
categoricals.vec <- c(categoricals.vec, colnames(trainData)[grep(paste(oneHotVar, collapse = "|"), colnames(trainData))])
#- 범주형(순서형) 변환
ordered_var1 <- colnames(train)[grep("Q.A", colnames(train))]
ordered_var2 <- colnames(train)[grep("tp|wr|wf.", colnames(train))]
categoricals.vec <- c(ordered_var1, ordered_var2)
categoricals.vec <- c(categoricals.vec, colnames(trainData)[grep(paste(oneHotVar, collapse = "|"), colnames(trainData))])
model <-  lgb.train(
params = params.lgb
, data = dtrain
, valids = list(train = dtrain, test = dvalid)
, learning_rate = 0.001
, nrounds = 500
, early_stopping_rounds = 40
, eval_freq = 20
, categorical_feature = categoricals.vec
)
model
model
